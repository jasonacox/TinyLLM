# Create vLLM docker image with CUDA 12.1.0 and Ubuntu 22.04
# 
# This is used to build vLLM from source, which is necessary for 
# the Pascal architecture (e.g. GTX 1060, Tesla P100).
#
# Prerequisites:
#   - NVIDIA driver and CUDA toolkit installed on host
#   - Install and moeidfy vllm source:
#       git clone https://github.com/vllm-project/vllm.git
#       cd vllm
#       edit setup.py to add 6.0, 6.1, 6.2 o CUDA_ARCHITECTURES and
#            change 'if major < 7:' to 'if major < 6:' 
#
# Author: Jason A. Cox,
# Date: 27-Jan-2024
# https://github.com/jasonacox/TinyLLM

FROM nvidia/cuda:12.1.0-devel-ubuntu22.04
RUN apt-get update -y \
     && apt-get install -y python3-pip
WORKDIR /app
COPY . .
RUN python3 -m pip install -e .
EXPOSE 8000
COPY entrypoint.sh /usr/local/bin/
CMD [ "entrypoint.sh" ]